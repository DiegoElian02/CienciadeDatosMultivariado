{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57152252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11373ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date       PM10      PM2.5         O3         NO        NO2  \\\n",
      "0  2018-01-01  16.708333   7.833333  10.500000  20.170833   6.775000   \n",
      "1  2018-01-02  31.333333  13.708333   7.375000  42.754167  17.204167   \n",
      "2  2018-01-03  60.583333  16.666667  10.916667  62.720833  22.862500   \n",
      "\n",
      "         NOx  SO2    CO         PRS         RH      TOUT        SR        WSR  \\\n",
      "0  26.604167  5.6  0.92  725.358333  90.708333  2.910833  0.022583  11.775000   \n",
      "1  59.037500  5.6  0.92  723.241667  95.541667  0.858750  0.016417   6.308333   \n",
      "2  84.795833  5.6  0.92  723.762500  73.375000  4.810000  0.109875   6.875000   \n",
      "\n",
      "         WDR     RAINF  \n",
      "0  51.291667  0.001250  \n",
      "1  75.250000  0.001667  \n",
      "2  71.125000  0.000000  \n",
      "Training set shape == (1333, 16)\n",
      "All timestamps == 1333\n",
      "Featured selected: ['PM10', 'PM2.5', 'O3', 'NO', 'NO2']\n",
      "         date       PM10      PM2.5         O3         NO        NO2  \\\n",
      "0  2018-01-01  16.708333   7.833333  10.500000  20.170833   6.775000   \n",
      "1  2018-01-02  31.333333  13.708333   7.375000  42.754167  17.204167   \n",
      "2  2018-01-03  60.583333  16.666667  10.916667  62.720833  22.862500   \n",
      "3  2018-01-04  87.583333  29.500000  16.083333  60.962500  26.304167   \n",
      "4  2018-01-05  82.083333  29.208333  16.333333  36.108333  29.508333   \n",
      "\n",
      "         NOx  SO2    CO         PRS         RH       TOUT        SR  \\\n",
      "0  26.604167  5.6  0.92  725.358333  90.708333   2.910833  0.022583   \n",
      "1  59.037500  5.6  0.92  723.241667  95.541667   0.858750  0.016417   \n",
      "2  84.795833  5.6  0.92  723.762500  73.375000   4.810000  0.109875   \n",
      "3  86.033333  5.6  0.92  720.462500  55.125000   8.817500  0.144083   \n",
      "4  65.400000  5.6  0.92  720.233333  65.083333  11.551667  0.117500   \n",
      "\n",
      "         WSR         WDR     RAINF  \n",
      "0  11.775000   51.291667  0.001250  \n",
      "1   6.308333   75.250000  0.001667  \n",
      "2   6.875000   71.125000  0.000000  \n",
      "3   6.054167  173.750000  0.000000  \n",
      "4   5.758333   95.208333  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Importing Training Set\n",
    "dataset_train = pd.read_csv('DatosDiarios.csv')\n",
    "dataset_train.fillna(method='ffill', inplace=True)\n",
    "print(dataset_train.head(3))\n",
    "#print(dataset_train.head())\n",
    "\n",
    "# Select features (columns) to be involved intro training and predictions\n",
    "cols = list(dataset_train)[1:6] #toma desde la segunda columna (Ã­ndice = 1)\n",
    "\n",
    "# Extract dates (will be used in visualization)\n",
    "datelist_train = list(dataset_train['date']) #lo pasa a lista\n",
    "datelist_train = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in datelist_train] #lo pasa a formato datatime.date\n",
    "\n",
    "print('Training set shape == {}'.format(dataset_train.shape))\n",
    "print('All timestamps == {}'.format(len(datelist_train)))\n",
    "print('Featured selected: {}'.format(cols))\n",
    "print(dataset_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49d9de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set == (1333, 5).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16.70833333,  7.83333333, 10.5       , 20.17083333,  6.775     ],\n",
       "       [31.33333333, 13.70833333,  7.375     , 42.75416667, 17.20416667],\n",
       "       [60.58333333, 16.66666667, 10.91666667, 62.72083333, 22.8625    ],\n",
       "       ...,\n",
       "       [67.20833333, 13.16666667, 21.95833333,  5.99166667,  8.275     ],\n",
       "       [63.75      , 16.91666667, 21.        ,  7.25833333,  8.20833333],\n",
       "       [45.625     ,  9.54166667, 19.91666667,  6.77083333,  7.8       ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = dataset_train[cols].astype(str)\n",
    "\n",
    "for i in cols:\n",
    "    for j in range(0, len(dataset_train)):\n",
    "        dataset_train[i][j] = dataset_train[i][j].replace(',', '')\n",
    "\n",
    "dataset_train = dataset_train.astype(float) #hacerlo todo floats\n",
    "\n",
    "# Using multiple features (predictors)\n",
    "training_set = dataset_train.values #hace un array con los valores de las columnas\n",
    "\n",
    "print('Shape of training set == {}.'.format(training_set.shape))\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aa82702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7360261 ],\n",
       "       [-1.19565518],\n",
       "       [-0.11491335],\n",
       "       ...,\n",
       "       [ 0.12987006],\n",
       "       [ 0.00209004],\n",
       "       [-0.66760041]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "sc_predict = StandardScaler()\n",
    "sc_predict.fit_transform(training_set[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7f34412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (1320, 7, 4).\n",
      "y_train shape == (1320, 1).\n"
     ]
    }
   ],
   "source": [
    "# Creating a data structure with 90 timestamps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 7   # Number of days we want top predict into the future\n",
    "n_past = 7     # Number of past days we want to use to predict the future\n",
    "\n",
    "for i in range(n_past, len(training_set_scaled) - n_future +1):\n",
    "    X_train.append(training_set_scaled[i - n_past:i, 0:dataset_train.shape[1] - 1])\n",
    "    y_train.append(training_set_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print('X_train shape == {}.'.format(X_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a043fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and packages from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5640f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape == (1320, 7, 4).\n",
      "y_train shape == (1320, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: ReLu. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12620/1592300471.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Adding 2nd LSTM layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ReLu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, return_sequences, return_state, go_backwards, stateful, time_major, unroll, **kwargs)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_runtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return_runtime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m     super(LSTM, self).__init__(\n\u001b[0m\u001b[0;32m   1090\u001b[0m         \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1135\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_non_trackable_mask_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropoutRNNCellMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[0;32m   2795\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2796\u001b[0m       \u001b[0mcell_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2797\u001b[1;33m     cell = LSTMCell(\n\u001b[0m\u001b[0;32m   2798\u001b[0m         \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m         \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, **kwargs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2357\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2358\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecurrent_activation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecurrent_activation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(name, custom_objects)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[0mglobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m   return deserialize_keras_object(\n\u001b[0m\u001b[0;32m    556\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\elias\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    707\u001b[0m       \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    710\u001b[0m             \u001b[1;34mf'Unknown {printable_module_name}: {object_name}. Please ensure '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[1;34m'this object is passed to the `custom_objects` argument. See '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown activation function: ReLu. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# Creating a data structure with 90 timestamps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 7   # Number of days we want top predict into the future\n",
    "n_past = 7     # Number of past days we want to use to predict the future\n",
    "\n",
    "for i in range(n_past, len(training_set_scaled) - n_future +1):\n",
    "    X_train.append(training_set_scaled[i - n_past:i, 0:dataset_train.shape[1] - 1])\n",
    "    y_train.append(training_set_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print('X_train shape == {}.'.format(X_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initializing the Neural Network based on LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# Adding 1st LSTM layer\n",
    "model.add(LSTM(units=64, return_sequences=True, input_shape=(n_past, dataset_train.shape[1]-1)))\n",
    "\n",
    "\n",
    "# Adding 2nd LSTM layer\n",
    "model.add(LSTM(units=20, return_sequences=False, activation='ReLu'))\n",
    "\n",
    "\n",
    "\n",
    "# Adding Dropout\n",
    "model.add(Dropout(0.55))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=0.005), loss='mean_squared_error')\n",
    "#es = EarlyStopping(monitor='accuracy', min_delta=1e-10, patience=10, verbose=1)\n",
    "#rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "#mcp = ModelCheckpoint(filepath='weights.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "#tb = TensorBoard('logs')\n",
    "\n",
    "history = model.fit(X_train, y_train, shuffle=True, epochs=100, validation_split=0.2, verbose=1, batch_size=256)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate list of sequence of days for predictions\n",
    "datelist_future = pd.date_range(datelist_train[-1], periods=n_future, freq='1d').tolist() #crea lista de los siguientes dÃ­as, indicado anteriormente\n",
    "#print(datelist_future)\n",
    "\n",
    "'''\n",
    "Remeber, we have datelist_train from begining.\n",
    "'''\n",
    "\n",
    "# Convert Pandas Timestamp to Datetime object (for transformation) --> FUTURE\n",
    "datelist_future_ = []\n",
    "for this_timestamp in datelist_future:\n",
    "    datelist_future_.append(this_timestamp.date())\n",
    "\n",
    "#print(datelist_future_)\n",
    "\n",
    "\n",
    "\n",
    "# Perform predictions\n",
    "predictions_future = model.predict(X_train[-n_future:])\n",
    "\n",
    "predictions_train = model.predict(X_train[n_past:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Inverse the predictions to original measurements\n",
    "\n",
    "# ---> Special function: convert <datetime.date> to <Timestamp>\n",
    "def datetime_to_timestamp(x):\n",
    "    '''\n",
    "        x : a given datetime value (datetime.date)\n",
    "    '''\n",
    "    return datetime.strptime(x.strftime('%Y%m%d'), '%Y%m%d')\n",
    "\n",
    "\n",
    "y_pred_future = sc_predict.inverse_transform(predictions_future)\n",
    "y_pred_train = sc_predict.inverse_transform(predictions_train)\n",
    "\n",
    "PREDICTIONS_FUTURE = pd.DataFrame(y_pred_future, columns=['Precio/Litro']).set_index(pd.Series(datelist_future))\n",
    "PREDICTION_TRAIN = pd.DataFrame(y_pred_train, columns=['Precio/Litro']).set_index(pd.Series(datelist_train[2 * n_past + n_future -1:]))\n",
    "\n",
    "# Convert <datetime.date> to <Timestamp> for PREDCITION_TRAIN\n",
    "PREDICTION_TRAIN.index = PREDICTION_TRAIN.index.to_series().apply(datetime_to_timestamp)\n",
    "\n",
    "PREDICTION_TRAIN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set plot size \n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "\n",
    "# Plot parameters\n",
    "START_DATE_FOR_PLOTTING = '2018'\n",
    "\n",
    "plt.plot(dataset_train.loc[START_DATE_FOR_PLOTTING:].index+17400, dataset_train.loc[START_DATE_FOR_PLOTTING:]['PM10'], color='b', label='Actual Stock Price')\n",
    "plt.plot(PREDICTIONS_FUTURE.index, PREDICTIONS_FUTURE['Precio/Litro'], color='r', label='Predicted Gas Price')\n",
    "plt.plot(PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:].index, PREDICTION_TRAIN.loc[START_DATE_FOR_PLOTTING:]['Precio/Litro'], color='orange', label='Training predictions')\n",
    "\n",
    "plt.axvline(x = min(PREDICTIONS_FUTURE.index), color='green', linewidth=2, linestyle='--')\n",
    "\n",
    "plt.grid(which='major', color='#cccccc', alpha=0.5)\n",
    "\n",
    "plt.legend(shadow=True)\n",
    "plt.title('Predcitions Gas Prices', family='Arial', fontsize=12)\n",
    "plt.xlabel('Timeline', family='Arial', fontsize=10)\n",
    "plt.ylabel('Gas Price Value', family='Arial', fontsize=10)\n",
    "plt.xticks(rotation=45, fontsize=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94ea7606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53ad13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "258996d679d8e259ac990df9fdfc128ec5eb77c39bd98f0b9ba2b9004f62dd43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
